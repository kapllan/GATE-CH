{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73684908-9c4e-4ef3-afcd-5253473cb173",
   "metadata": {},
   "source": [
    "Specify where your evaluation results are saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a90ee10-07f3-4c38-bc1e-60d4db6860ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_results = f\"./llm_prompting_evaluation_results/VAGOsolutions/SauerkrautLM-Mixtral-8x7B-Instruct/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "461ad9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'precision_macro':'Macro-P', \n",
    "           'precision_micro':'Micro-P',\n",
    "           'recall_macro':'Macro-R', \n",
    "           'recall_micro':'Micro-R', \n",
    "           'f1_macro':'Macro-F1', \n",
    "           'f1_micro':'Micro-F1', \n",
    "           'prompt_1':'1', \n",
    "           'prompt_2':'2', \n",
    "           'prompt_3':'3',\n",
    "           'prompt_4':'4',\n",
    "           'kriterium':'AC',\n",
    "          'gewichtung':'W',\n",
    "          'maxPunkte':'MNP',\n",
    "          'zkNummer':'ID'}\n",
    "prompt_id_list = ['prompt_1', 'prompt_2', 'prompt_3', 'prompt_4']\n",
    "averages = ['macro', 'micro']\n",
    "scores = ['precision', 'recall', 'f1']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47f060c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'training_data_handler'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Literal\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtraining_data_handler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainingDataHandler\n\u001b[1;32m     12\u001b[0m tdh \u001b[38;5;241m=\u001b[39m TrainingDataHandler()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'training_data_handler'"
     ]
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "import json as js\n",
    "import re\n",
    "from statistics import harmonic_mean, mean\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, matthews_corrcoef\n",
    "from typing import Literal\n",
    "import sys\n",
    "\n",
    "from training_data_handler import TrainingDataHandler\n",
    "\n",
    "tdh = TrainingDataHandler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df37cb86-7a14-4539-98d0-aac048db46b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of labels for train set.\n",
      "             label  text\n",
      "0     has_criteria    32\n",
      "1  has_no_criteria    32\n",
      "Distribution of labels for validation set.\n",
      "             label  text\n",
      "0     has_criteria    66\n",
      "1  has_no_criteria    63\n",
      "Distribution of labels for test set.\n",
      "             label  text\n",
      "0     has_criteria    66\n",
      "1  has_no_criteria    64\n"
     ]
    }
   ],
   "source": [
    "dataset = tdh.get_criteria_relevance_training_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7e03b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to highlight the max value in each column, but only for numeric columns\n",
    "def highlight_max_numeric(s):\n",
    "    '''\n",
    "    Highlight the maximum in a Series yellow if it's numeric.\n",
    "    '''\n",
    "    if s.dtype in ['int', 'float']:\n",
    "        is_max = s == s.max()\n",
    "        return ['background-color: yellow' if v else '' for v in is_max]\n",
    "    else:\n",
    "        return ['' for _ in s]\n",
    "    \n",
    "def bold_max_values(data):\n",
    "    # Create a copy of the DataFrame to avoid modifying the original data\n",
    "    df_temp = data.copy()\n",
    "    for column in df_temp.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df_temp[column]):\n",
    "            # Find the maximum value in the column\n",
    "            max_value = df_temp[column].max()\n",
    "            # Apply LaTeX bold formatting to the max value\n",
    "            df_temp[column] = df_temp[column].apply(lambda x: f'\\\\textbf{{{x}}}' if x == max_value else x)\n",
    "    \n",
    "    columns = df_temp.columns.tolist()\n",
    "    for x in columns:\n",
    "        df_temp.rename(columns={x: f'\\\\textbf{{{x}}}'}, inplace=True)\n",
    "    return df_temp\n",
    "\n",
    "\n",
    "def make_columns_bold(data):\n",
    "    \n",
    "    df_temp = data.copy()\n",
    "    \n",
    "    columns = df_temp.columns.tolist()\n",
    "    for x in columns:\n",
    "        df_temp.rename(columns={x: f'\\\\textbf{{{x}}}'}, inplace=True)\n",
    "    return df_temp\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93654144",
   "metadata": {},
   "source": [
    "# Detecting binary criteria presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526c5278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_table(y_true, y_pred, split):\n",
    "    f1_macro = f1_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
    "    f1_micro = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    precision_macro = precision_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
    "    precision_micro = precision_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    recall_macro = precision_score(y_true=y_true, y_pred=y_pred, average='macro')\n",
    "    recall_micro = precision_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    mcc = matthews_corrcoef(y_true=y_true, y_pred=y_pred)\n",
    "\n",
    "    classificatio_results = list()\n",
    "    classificatio_results.append({'Metric':'ACC',split:accuracy})\n",
    "    classificatio_results.append({'Metric':'Macro-F1',split:f1_macro})\n",
    "    classificatio_results.append({'Metric':'Micro-F1',split:f1_micro})\n",
    "    classificatio_results.append({'Metric':'Macro-P',split:precision_macro})\n",
    "    classificatio_results.append({'Metric':'Micro-P',split:precision_micro})\n",
    "    classificatio_results.append({'Metric':'Macro-R',split:recall_macro})\n",
    "    classificatio_results.append({'Metric':'Micro-R',split:recall_macro})\n",
    "    classificatio_results.append({'Metric':'MCC',split:mcc})\n",
    "    results = pd.DataFrame(classificatio_results)\n",
    "\n",
    "    results[split]=results[split].apply(lambda x: round(x*100, 2))\n",
    "    return results\n",
    "\n",
    "def evaluate_llm_binary_classification(prompt_id=Literal['prompt_1', 'prompt_2', 'prompt_3', 'prompt_4']):\n",
    "    df = pd.read_excel(f\"{path_to_results}/{prompt_id}/evaluation_results_all.xlsx\")\n",
    "    # ALL\n",
    "    y_true = df.label.tolist()\n",
    "    y_true = [1 if x=='has_criteria' else 0 for x in y_true]\n",
    "    y_pred = df.label_predicted.tolist()\n",
    "    y_pred = [1 if x=='has_criteria' else 0 for x in y_pred]\n",
    "    \n",
    "    results_all = get_result_table(y_true, y_pred, 'All')\n",
    "    \n",
    "    # Validation\n",
    "    validation_contexts = dataset['validation'].filename.tolist()\n",
    "    df_filtered = df[df.filename.isin(validation_contexts)]\n",
    "    y_true = df_filtered.label.tolist()\n",
    "    y_true = [1 if x=='has_criteria' else 0 for x in y_true]\n",
    "    y_pred = df_filtered.label_predicted.tolist()\n",
    "    y_pred = [1 if x=='has_criteria' else 0 for x in y_pred]\n",
    "    results_validation = get_result_table(y_true, y_pred, 'Validation')\n",
    "    del results_validation['Metric']\n",
    "    \n",
    "    # Test\n",
    "    test_contexts = dataset['test'].filename.tolist()\n",
    "    df_filtered = df[df.filename.isin(test_contexts)]\n",
    "    y_true = df_filtered.label.tolist()\n",
    "    y_true = [1 if x=='has_criteria' else 0 for x in y_true]\n",
    "    y_pred = df_filtered.label_predicted.tolist()\n",
    "    y_pred = [1 if x=='has_criteria' else 0 for x in y_pred]\n",
    "    results_test = get_result_table(y_true, y_pred, 'Test')\n",
    "    del results_test['Metric']\n",
    "    \n",
    "    results_combined = pd.concat([results_validation, results_test, results_all ],axis=1)\n",
    "    results_combined = results_combined[['Metric', 'Validation', 'Test', 'All']]\n",
    "    return results_combined\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12f6cb3f-d5a6-4b58-99e3-e67cb989389c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_llm_binary_classification' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m llm_binary_clf_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_llm_binary_classification\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt_1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m llm_binary_clf_results\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluate_llm_binary_classification' is not defined"
     ]
    }
   ],
   "source": [
    "llm_binary_clf_results = evaluate_llm_binary_classification('prompt_1')\n",
    "llm_binary_clf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "52ada1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "Metric & Validation & Test & All \\\\\n",
      "\\midrule\n",
      "ACC & 91.47 & 93.08 & 92.07 \\\\\n",
      "Macro-F1 & 91.37 & 93.04 & 92.01 \\\\\n",
      "Micro-F1 & 91.47 & 93.08 & 92.07 \\\\\n",
      "Macro-P & 92.86 & 93.64 & 93.09 \\\\\n",
      "Micro-P & 91.47 & 93.08 & 92.07 \\\\\n",
      "Macro-R & 92.86 & 93.64 & 93.09 \\\\\n",
      "Micro-R & 92.86 & 93.64 & 93.09 \\\\\n",
      "MCC & 84.11 & 86.63 & 85.02 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(llm_binary_clf_results.to_latex(index=False, float_format=\"{:.2f}\".format))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aedc13a",
   "metadata": {},
   "source": [
    "# Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71c08f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "\\textbf{Prompt} & \\textbf{Criteria Presence} & \\textbf{Metric} & \\textbf{AC} & \\textbf{ID} & \\textbf{MNP} & \\textbf{W} \\\\\n",
      "\\midrule\n",
      "1 & mixed & Macro-P & 34.04 & 36.77 & 41.97 & 44.53 \\\\\n",
      "2 & mixed & Macro-P & 37.35 & 38.23 & 44.86 & 48.20 \\\\\n",
      "3 & mixed & Macro-P & 37.68 & 40.67 & 43.07 & 26.81 \\\\\n",
      "4 & mixed & Macro-P & 43.89 & 47.82 & 52.93 & 55.11 \\\\\n",
      "1 & with ACs only & Macro-P & 64.45 & 69.83 & 80.03 & 85.07 \\\\\n",
      "2 & with ACs only & Macro-P & \\textbf{64.98} & 66.71 & 79.73 & 86.29 \\\\\n",
      "3 & with ACs only & Macro-P & 60.83 & 66.10 & 66.02 & 34.09 \\\\\n",
      "4 & with ACs only & Macro-P & 64.64 & \\textbf{72.36} & \\textbf{82.39} & \\textbf{86.69} \\\\\n",
      "1 & without ACs only & Macro-P & 2.48 & 2.48 & 2.48 & 2.48 \\\\\n",
      "2 & without ACs only & Macro-P & 8.70 & 8.70 & 8.70 & 8.70 \\\\\n",
      "3 & without ACs only & Macro-P & 13.66 & 14.29 & 19.25 & 19.25 \\\\\n",
      "4 & without ACs only & Macro-P & 22.36 & 22.36 & 22.36 & 22.36 \\\\\n",
      "1 & mixed & Micro-P & 40.53 & 40.05 & 43.22 & 48.26 \\\\\n",
      "2 & mixed & Micro-P & 43.91 & 41.73 & 46.40 & 51.97 \\\\\n",
      "3 & mixed & Micro-P & 43.93 & 44.38 & 45.24 & 31.40 \\\\\n",
      "4 & mixed & Micro-P & 50.73 & 51.09 & 54.58 & 59.27 \\\\\n",
      "1 & with ACs only & Micro-P & 77.21 & 76.27 & 82.49 & 92.39 \\\\\n",
      "2 & with ACs only & Micro-P & 77.87 & 73.58 & 82.75 & 93.69 \\\\\n",
      "3 & with ACs only & Micro-P & 73.11 & 73.39 & 70.30 & 43.11 \\\\\n",
      "4 & with ACs only & Micro-P & \\textbf{78.07} & \\textbf{78.79} & \\textbf{85.65} & \\textbf{94.85} \\\\\n",
      "1 & without ACs only & Micro-P & 2.48 & 2.48 & 2.48 & 2.48 \\\\\n",
      "2 & without ACs only & Micro-P & 8.70 & 8.70 & 8.70 & 8.70 \\\\\n",
      "3 & without ACs only & Micro-P & 13.66 & 14.29 & 19.25 & 19.25 \\\\\n",
      "4 & without ACs only & Micro-P & 22.36 & 22.36 & 22.36 & 22.36 \\\\\n",
      "1 & mixed & Macro-R & 34.04 & 36.77 & 41.97 & 44.53 \\\\\n",
      "2 & mixed & Macro-R & 37.35 & 38.23 & 44.86 & 48.20 \\\\\n",
      "3 & mixed & Macro-R & 37.68 & 40.67 & 43.07 & 26.81 \\\\\n",
      "4 & mixed & Macro-R & 43.89 & 47.82 & 52.93 & 55.11 \\\\\n",
      "1 & with ACs only & Macro-R & 64.45 & 69.83 & 80.03 & 85.07 \\\\\n",
      "2 & with ACs only & Macro-R & \\textbf{64.98} & 66.71 & 79.73 & 86.29 \\\\\n",
      "3 & with ACs only & Macro-R & 60.83 & 66.10 & 66.02 & 34.09 \\\\\n",
      "4 & with ACs only & Macro-R & 64.64 & \\textbf{72.36} & \\textbf{82.39} & \\textbf{86.69} \\\\\n",
      "1 & without ACs only & Macro-R & 2.48 & 2.48 & 2.48 & 2.48 \\\\\n",
      "2 & without ACs only & Macro-R & 8.70 & 8.70 & 8.70 & 8.70 \\\\\n",
      "3 & without ACs only & Macro-R & 13.66 & 14.29 & 19.25 & 19.25 \\\\\n",
      "4 & without ACs only & Macro-R & 22.36 & 22.36 & 22.36 & 22.36 \\\\\n",
      "1 & mixed & Micro-R & 37.06 & 37.76 & 45.30 & 45.73 \\\\\n",
      "2 & mixed & Micro-R & 40.26 & 39.12 & 47.71 & 49.01 \\\\\n",
      "3 & mixed & Micro-R & 40.71 & 41.32 & 43.43 & 27.19 \\\\\n",
      "4 & mixed & Micro-R & 46.67 & 48.41 & 55.47 & 56.27 \\\\\n",
      "1 & with ACs only & Micro-R & 70.40 & 71.77 & 86.57 & 87.43 \\\\\n",
      "2 & with ACs only & Micro-R & \\textbf{70.68} & 68.45 & 85.33 & 87.88 \\\\\n",
      "3 & with ACs only & Micro-R & 66.79 & 67.38 & 66.73 & 34.84 \\\\\n",
      "4 & with ACs only & Micro-R & 70.11 & \\textbf{73.52} & \\textbf{87.4} & \\textbf{88.96} \\\\\n",
      "1 & without ACs only & Micro-R & 2.48 & 2.48 & 2.48 & 2.48 \\\\\n",
      "2 & without ACs only & Micro-R & 8.70 & 8.70 & 8.70 & 8.70 \\\\\n",
      "3 & without ACs only & Micro-R & 13.66 & 14.29 & 19.25 & 19.25 \\\\\n",
      "4 & without ACs only & Micro-R & 22.36 & 22.36 & 22.36 & 22.36 \\\\\n",
      "1 & mixed & Macro-F1 & 34.04 & 36.77 & 41.97 & 44.53 \\\\\n",
      "2 & mixed & Macro-F1 & 37.35 & 38.23 & 44.86 & 48.20 \\\\\n",
      "3 & mixed & Macro-F1 & 37.68 & 40.67 & 43.07 & 26.81 \\\\\n",
      "4 & mixed & Macro-F1 & 43.89 & 47.82 & 52.93 & 55.11 \\\\\n",
      "1 & with ACs only & Macro-F1 & 64.45 & 69.83 & 80.03 & 85.07 \\\\\n",
      "2 & with ACs only & Macro-F1 & \\textbf{64.98} & 66.71 & 79.73 & 86.29 \\\\\n",
      "3 & with ACs only & Macro-F1 & 60.83 & 66.10 & 66.02 & 34.09 \\\\\n",
      "4 & with ACs only & Macro-F1 & 64.64 & \\textbf{72.36} & \\textbf{82.39} & \\textbf{86.69} \\\\\n",
      "1 & without ACs only & Macro-F1 & 2.48 & 2.48 & 2.48 & 2.48 \\\\\n",
      "2 & without ACs only & Macro-F1 & 8.70 & 8.70 & 8.70 & 8.70 \\\\\n",
      "3 & without ACs only & Macro-F1 & 13.66 & 14.29 & 19.25 & 19.25 \\\\\n",
      "4 & without ACs only & Macro-F1 & 22.36 & 22.36 & 22.36 & 22.36 \\\\\n",
      "1 & mixed & Micro-F1 & 38.03 & 38.43 & 43.49 & 46.52 \\\\\n",
      "2 & mixed & Micro-F1 & 41.33 & 39.95 & 46.43 & 50.03 \\\\\n",
      "3 & mixed & Micro-F1 & 41.42 & 42.23 & 43.79 & 28.14 \\\\\n",
      "4 & mixed & Micro-F1 & 47.95 & 49.36 & 54.41 & 57.20 \\\\\n",
      "1 & with ACs only & Micro-F1 & 72.29 & 73.09 & 83.01 & 88.97 \\\\\n",
      "2 & with ACs only & Micro-F1 & \\textbf{72.79} & 70.08 & 82.80 & 89.88 \\\\\n",
      "3 & with ACs only & Micro-F1 & 68.18 & 69.17 & 67.44 & 36.71 \\\\\n",
      "4 & with ACs only & Micro-F1 & 72.62 & \\textbf{75.4} & \\textbf{85.31} & \\textbf{90.78} \\\\\n",
      "1 & without ACs only & Micro-F1 & 2.48 & 2.48 & 2.48 & 2.48 \\\\\n",
      "2 & without ACs only & Micro-F1 & 8.70 & 8.70 & 8.70 & 8.70 \\\\\n",
      "3 & without ACs only & Micro-F1 & 13.66 & 14.29 & 19.25 & 19.25 \\\\\n",
      "4 & without ACs only & Micro-F1 & 22.36 & 22.36 & 22.36 & 22.36 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def make_ner_overview(averages, scores):\n",
    "    # averages = ['macro']\n",
    "    # scores = ['f1']\n",
    "\n",
    "    all_results = list()\n",
    "\n",
    "    for prompt_id in prompt_id_list:\n",
    "        df = pd.read_excel(path_to_results+f\"{prompt_id}/evaluation_results_all.xlsx\")\n",
    "\n",
    "        span_scores = df.span_scores.tolist()\n",
    "        span_scores = [literal_eval(x) for x in span_scores]\n",
    "\n",
    "\n",
    "        for average in averages:\n",
    "            for m in scores:\n",
    "                metrics =  dict()\n",
    "                m = m+'_'+average\n",
    "                key = mapping[m]\n",
    "                metrics['Prompt']=mapping[prompt_id]\n",
    "                metrics['Criteria Presence']='mixed'\n",
    "                metrics['Metric']=key\n",
    "                for label in ['kriterium', 'gewichtung', 'maxPunkte', 'zkNummer']:\n",
    "                    hmean = mean([x[label][m] for x in span_scores])*100\n",
    "                    hmean = round(hmean,2)\n",
    "                    metrics[mapping[label]]= hmean\n",
    "                    all_results.append(metrics)\n",
    "\n",
    "\n",
    "        df = pd.read_excel(path_to_results+f\"{prompt_id}/evaluation_results_has_criteria.xlsx\")\n",
    "\n",
    "        span_scores = df.span_scores.tolist()\n",
    "        span_scores = [literal_eval(x) for x in span_scores]\n",
    "\n",
    "\n",
    "        for average in averages:\n",
    "            for m in scores:\n",
    "                metrics =  dict()\n",
    "                m = m+'_'+average\n",
    "                key = mapping[m]\n",
    "                metrics['Prompt']=mapping[prompt_id]\n",
    "                metrics['Criteria Presence']='with ACs only'\n",
    "                metrics['Metric']=key\n",
    "                for label in ['kriterium', 'gewichtung', 'maxPunkte', 'zkNummer']:\n",
    "                    hmean = mean([x[label][m] for x in span_scores])*100\n",
    "                    hmean = round(hmean,2)\n",
    "                    metrics[mapping[label]]= hmean\n",
    "                    all_results.append(metrics)\n",
    "                    \n",
    "        \n",
    "        df = pd.read_excel(path_to_results+f\"{prompt_id}/evaluation_results_has_no_criteria.xlsx\")\n",
    "\n",
    "        span_scores = df.span_scores.tolist()\n",
    "        span_scores = [literal_eval(x) for x in span_scores]\n",
    "\n",
    "\n",
    "        for average in averages:\n",
    "            for m in scores:\n",
    "                metrics =  dict()\n",
    "                m = m+'_'+average\n",
    "                key = mapping[m]\n",
    "                metrics['Prompt']=mapping[prompt_id]\n",
    "                metrics['Criteria Presence']='without ACs only'\n",
    "                metrics['Metric']=key\n",
    "                for label in ['kriterium', 'gewichtung', 'maxPunkte', 'zkNummer']:\n",
    "                    hmean = mean([x[label][m] for x in span_scores])*100\n",
    "                    hmean = round(hmean,2)\n",
    "                    metrics[mapping[label]]= hmean\n",
    "                    all_results.append(metrics)\n",
    "\n",
    "\n",
    "    all_results_df = pd.DataFrame(all_results).sort_values(['Criteria Presence', 'Prompt']).drop_duplicates()\n",
    "    all_results_df = all_results_df[['Prompt', 'Criteria Presence', 'Metric', 'AC', 'ID', 'MNP', 'W', ]]\n",
    "    all_results_ner = bold_max_values(all_results_df)\n",
    "    return all_results_ner\n",
    "\n",
    "all_results_ner_combined = []\n",
    "for score in scores:\n",
    "    for average in averages:\n",
    "        res = make_ner_overview(averages=[average], scores=[score])\n",
    "        all_results_ner_combined.append(res)\n",
    "\n",
    "\n",
    "all_results_ner_combined = pd.concat(all_results_ner_combined, axis=0)\n",
    "\n",
    "# del all_results_ner_combined['\\\\textbf{Metric}']\n",
    "\n",
    "#all_results_ner_combined = all_results_ner_combined.sort_values(['\\\\textbf{Criteria Presence}', '\\\\textbf{Prompt}'])\n",
    "\n",
    "print(all_results_ner_combined.to_latex(index=False, float_format=\"{:.2f}\".format))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fbfe62dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>\\textbf{Prompt}</th>\n",
       "      <th>\\textbf{Criteria Presence}</th>\n",
       "      <th>\\textbf{Metric}</th>\n",
       "      <th>\\textbf{AC}</th>\n",
       "      <th>\\textbf{ID}</th>\n",
       "      <th>\\textbf{MNP}</th>\n",
       "      <th>\\textbf{W}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>mixed</td>\n",
       "      <td>Macro-P</td>\n",
       "      <td>34.04</td>\n",
       "      <td>36.77</td>\n",
       "      <td>41.97</td>\n",
       "      <td>44.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>mixed</td>\n",
       "      <td>Macro-P</td>\n",
       "      <td>37.35</td>\n",
       "      <td>38.23</td>\n",
       "      <td>44.86</td>\n",
       "      <td>48.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>mixed</td>\n",
       "      <td>Macro-P</td>\n",
       "      <td>37.68</td>\n",
       "      <td>40.67</td>\n",
       "      <td>43.07</td>\n",
       "      <td>26.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4</td>\n",
       "      <td>mixed</td>\n",
       "      <td>Macro-P</td>\n",
       "      <td>43.89</td>\n",
       "      <td>47.82</td>\n",
       "      <td>52.93</td>\n",
       "      <td>55.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>with ACs only</td>\n",
       "      <td>Macro-P</td>\n",
       "      <td>64.45</td>\n",
       "      <td>69.83</td>\n",
       "      <td>80.03</td>\n",
       "      <td>85.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4</td>\n",
       "      <td>with ACs only</td>\n",
       "      <td>Micro-F1</td>\n",
       "      <td>72.62</td>\n",
       "      <td>\\textbf{75.4}</td>\n",
       "      <td>\\textbf{85.31}</td>\n",
       "      <td>\\textbf{90.78}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>without ACs only</td>\n",
       "      <td>Micro-F1</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>without ACs only</td>\n",
       "      <td>Micro-F1</td>\n",
       "      <td>8.7</td>\n",
       "      <td>8.7</td>\n",
       "      <td>8.7</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>without ACs only</td>\n",
       "      <td>Micro-F1</td>\n",
       "      <td>13.66</td>\n",
       "      <td>14.29</td>\n",
       "      <td>19.25</td>\n",
       "      <td>19.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4</td>\n",
       "      <td>without ACs only</td>\n",
       "      <td>Micro-F1</td>\n",
       "      <td>22.36</td>\n",
       "      <td>22.36</td>\n",
       "      <td>22.36</td>\n",
       "      <td>22.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   \\textbf{Prompt} \\textbf{Criteria Presence} \\textbf{Metric} \\textbf{AC}  \\\n",
       "0                1                      mixed         Macro-P       34.04   \n",
       "12               2                      mixed         Macro-P       37.35   \n",
       "24               3                      mixed         Macro-P       37.68   \n",
       "36               4                      mixed         Macro-P       43.89   \n",
       "4                1              with ACs only         Macro-P       64.45   \n",
       "..             ...                        ...             ...         ...   \n",
       "40               4              with ACs only        Micro-F1       72.62   \n",
       "8                1           without ACs only        Micro-F1        2.48   \n",
       "20               2           without ACs only        Micro-F1         8.7   \n",
       "32               3           without ACs only        Micro-F1       13.66   \n",
       "44               4           without ACs only        Micro-F1       22.36   \n",
       "\n",
       "      \\textbf{ID}    \\textbf{MNP}      \\textbf{W}  \n",
       "0           36.77           41.97           44.53  \n",
       "12          38.23           44.86            48.2  \n",
       "24          40.67           43.07           26.81  \n",
       "36          47.82           52.93           55.11  \n",
       "4           69.83           80.03           85.07  \n",
       "..            ...             ...             ...  \n",
       "40  \\textbf{75.4}  \\textbf{85.31}  \\textbf{90.78}  \n",
       "8            2.48            2.48            2.48  \n",
       "20            8.7             8.7             8.7  \n",
       "32          14.29           19.25           19.25  \n",
       "44          22.36           22.36           22.36  \n",
       "\n",
       "[72 rows x 7 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results_ner_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3b5870",
   "metadata": {},
   "source": [
    "# Relation Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00a71066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "\\textbf{Prompt} & \\textbf{Criteria Presence} & \\textbf{Macro-F1} & \\textbf{Micro-F1} \\\\\n",
      "\\midrule\n",
      "1 & mixed & 21.00 & 24.19 \\\\\n",
      "2 & mixed & 23.76 & 26.74 \\\\\n",
      "3 & mixed & 13.51 & 14.79 \\\\\n",
      "4 & mixed & 33.15 & 36.35 \\\\\n",
      "1 & with criteria only & 39.46 & 45.71 \\\\\n",
      "2 & with criteria only & 38.28 & 44.14 \\\\\n",
      "3 & with criteria only & 13.36 & 15.87 \\\\\n",
      "4 & with criteria only & \\textbf{43.56} & \\textbf{49.84} \\\\\n",
      "1 & without criteria only & 1.86 & 1.86 \\\\\n",
      "2 & without criteria only & 8.70 & 8.70 \\\\\n",
      "3 & without criteria only & 13.66 & 13.66 \\\\\n",
      "4 & without criteria only & 22.36 & 22.36 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def make_re_overview(averages, scores):\n",
    "    all_results = list()\n",
    "\n",
    "    for prompt_id in prompt_id_list:\n",
    "        df = pd.read_excel(path_to_results+f\"{prompt_id}/evaluation_results_all.xlsx\")\n",
    "        column_selected = df.key_value_eval.tolist()\n",
    "        key_value_eval = list()\n",
    "\n",
    "        for entry in column_selected:\n",
    "            entry = literal_eval(entry)\n",
    "            key_value_eval.append(entry)\n",
    "\n",
    "        with_criteria='mixed'\n",
    "        for mean_method in ['mean']:\n",
    "            metrics =  dict()\n",
    "            metrics['Prompt']=mapping[prompt_id]\n",
    "            metrics['Criteria Presence']=with_criteria\n",
    "            for average in averages:\n",
    "                for m in scores:\n",
    "                    m = m+'_'+average\n",
    "                    key = mapping[m]\n",
    "                    if mean_method == 'mean':\n",
    "                        hmean = mean([x[m] for x in key_value_eval])*100\n",
    "                        hmean = round(hmean,2)\n",
    "                        metrics[key]= hmean\n",
    "            all_results.append(metrics)\n",
    "\n",
    "        df = pd.read_excel(path_to_results+f\"{prompt_id}/evaluation_results_has_criteria.xlsx\")\n",
    "        column_selected = df.key_value_eval.tolist()\n",
    "        key_value_eval = list()\n",
    "\n",
    "        for entry in column_selected:\n",
    "            entry = literal_eval(entry)\n",
    "            key_value_eval.append(entry)\n",
    "\n",
    "        with_criteria='with criteria only'\n",
    "        for mean_method in ['mean']:\n",
    "            metrics =  dict()\n",
    "            metrics['Prompt']=mapping[prompt_id]\n",
    "            metrics['Criteria Presence']=with_criteria\n",
    "            for average in averages:\n",
    "                for m in scores:\n",
    "                    m = m+'_'+average\n",
    "                    key = mapping[m]\n",
    "                    if mean_method == 'mean':\n",
    "                        hmean = mean([x[m] for x in key_value_eval])*100\n",
    "                        hmean = round(hmean,2)\n",
    "                        metrics[key]= hmean\n",
    "            all_results.append(metrics)\n",
    "\n",
    "        df = pd.read_excel(path_to_results+f\"{prompt_id}/evaluation_results_has_no_criteria.xlsx\")\n",
    "        column_selected = df.key_value_eval.tolist()\n",
    "        key_value_eval = list()\n",
    "\n",
    "        for entry in column_selected:\n",
    "            entry = literal_eval(entry)\n",
    "            key_value_eval.append(entry)\n",
    "\n",
    "        with_criteria='without criteria only'\n",
    "        for mean_method in ['mean']:\n",
    "            metrics =  dict()\n",
    "            metrics['Prompt']=mapping[prompt_id]\n",
    "            metrics['Criteria Presence']=with_criteria\n",
    "            for average in averages:\n",
    "                for m in scores:\n",
    "                    m = m+'_'+average\n",
    "                    key = mapping[m]\n",
    "                    if mean_method == 'mean':\n",
    "                        hmean = mean([x[m] for x in key_value_eval])*100\n",
    "                        hmean = round(hmean,2)\n",
    "                        metrics[key]= hmean\n",
    "            all_results.append(metrics)\n",
    "\n",
    "    all_results_df = pd.DataFrame(all_results).sort_values(['Criteria Presence', 'Prompt'])\n",
    "    all_results_df = bold_max_values(all_results_df)\n",
    "    return all_results_df\n",
    "\n",
    "all_results_re_macro = make_re_overview(averages=['macro'], scores=['f1'])\n",
    "all_results_re_micro = make_re_overview(averages=['micro'], scores=['f1'])\n",
    "\n",
    "\n",
    "all_results_re_combined = pd.concat([all_results_re_macro, all_results_re_micro], axis=1)\n",
    "all_results_re_combined = all_results_re_macro.merge(all_results_re_micro, on=['\\\\textbf{Prompt}', '\\\\textbf{Criteria Presence}'])\n",
    "\n",
    "# del all_results_re_macro['\\\\textbf{Metric}']\n",
    "\n",
    "#all_results_ner_combined = all_results_ner_combined.sort_values(['\\\\textbf{Criteria Presence}', '\\\\textbf{Prompt}'])\n",
    "\n",
    "print(all_results_re_combined.to_latex(index=False, float_format=\"{:.2f}\".format))\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d26368d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>\\textbf{Prompt}</th>\n",
       "      <th>\\textbf{Criteria Presence}</th>\n",
       "      <th>\\textbf{Macro-F1}</th>\n",
       "      <th>\\textbf{Micro-F1}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>mixed</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>mixed</td>\n",
       "      <td>23.76</td>\n",
       "      <td>26.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>mixed</td>\n",
       "      <td>13.51</td>\n",
       "      <td>14.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>mixed</td>\n",
       "      <td>33.15</td>\n",
       "      <td>36.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>with criteria only</td>\n",
       "      <td>39.46</td>\n",
       "      <td>45.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>with criteria only</td>\n",
       "      <td>38.28</td>\n",
       "      <td>44.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>with criteria only</td>\n",
       "      <td>13.36</td>\n",
       "      <td>15.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>with criteria only</td>\n",
       "      <td>\\textbf{43.56}</td>\n",
       "      <td>\\textbf{49.84}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>without criteria only</td>\n",
       "      <td>1.86</td>\n",
       "      <td>1.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>without criteria only</td>\n",
       "      <td>8.7</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>without criteria only</td>\n",
       "      <td>13.66</td>\n",
       "      <td>13.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>without criteria only</td>\n",
       "      <td>22.36</td>\n",
       "      <td>22.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   \\textbf{Prompt} \\textbf{Criteria Presence} \\textbf{Macro-F1}  \\\n",
       "0                1                      mixed              21.0   \n",
       "1                2                      mixed             23.76   \n",
       "2                3                      mixed             13.51   \n",
       "3                4                      mixed             33.15   \n",
       "4                1         with criteria only             39.46   \n",
       "5                2         with criteria only             38.28   \n",
       "6                3         with criteria only             13.36   \n",
       "7                4         with criteria only    \\textbf{43.56}   \n",
       "8                1      without criteria only              1.86   \n",
       "9                2      without criteria only               8.7   \n",
       "10               3      without criteria only             13.66   \n",
       "11               4      without criteria only             22.36   \n",
       "\n",
       "   \\textbf{Micro-F1}  \n",
       "0              24.19  \n",
       "1              26.74  \n",
       "2              14.79  \n",
       "3              36.35  \n",
       "4              45.71  \n",
       "5              44.14  \n",
       "6              15.87  \n",
       "7     \\textbf{49.84}  \n",
       "8               1.86  \n",
       "9                8.7  \n",
       "10             13.66  \n",
       "11             22.36  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results_re_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b061b2da-a44a-42d0-b551-75a4ddc6ee93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70fddae9",
   "metadata": {},
   "source": [
    "# Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d722637f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrr}\n",
      "\\toprule\n",
      "\\textbf{Prompt} & \\textbf{Criteria Presence} & \\textbf{Successful} & \\textbf{Failed} \\\\\n",
      "\\midrule\n",
      "1 & mixed & 327 & 1 \\\\\n",
      "2 & mixed & 327 & 1 \\\\\n",
      "3 & mixed & 328 & 0 \\\\\n",
      "4 & mixed & 328 & 0 \\\\\n",
      "1 & with criteria only & 167 & 0 \\\\\n",
      "2 & with criteria only & 167 & 0 \\\\\n",
      "3 & with criteria only & 167 & 0 \\\\\n",
      "4 & with criteria only & 167 & 0 \\\\\n",
      "1 & without criteria only & 160 & 1 \\\\\n",
      "2 & without criteria only & 160 & 1 \\\\\n",
      "3 & without criteria only & 161 & 0 \\\\\n",
      "4 & without criteria only & 161 & 0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def make_formatting_overview():\n",
    "    all_results = list()\n",
    "\n",
    "    for prompt_id in prompt_id_list:\n",
    "\n",
    "        df = pd.read_excel(path_to_results+f\"{prompt_id}/evaluation_results_all.xlsx\")\n",
    "        entry = {\n",
    "                'Prompt':mapping[prompt_id],\n",
    "                'Criteria Presence': 'mixed',\n",
    "                'Successful':0,\n",
    "                'Failed':0\n",
    "                }\n",
    "        for row in df.to_dict(orient='records'):\n",
    "            if row['conversion_status']=='ok':\n",
    "                entry['Successful']+=1\n",
    "            if row['conversion_status']=='failed':\n",
    "                entry['Failed']+=1\n",
    "        all_results.append(entry)\n",
    "        \n",
    "        df = pd.read_excel(path_to_results+f\"{prompt_id}/evaluation_results_has_criteria.xlsx\")\n",
    "        entry = {\n",
    "                'Prompt':mapping[prompt_id],\n",
    "                'Criteria Presence': 'with criteria only',\n",
    "                'Successful':0,\n",
    "                'Failed':0\n",
    "                }\n",
    "        for row in df.to_dict(orient='records'):\n",
    "            if row['conversion_status']=='ok':\n",
    "                entry['Successful']+=1\n",
    "            if row['conversion_status']=='failed':\n",
    "                entry['Failed']+=1\n",
    "        all_results.append(entry)\n",
    "        \n",
    "        \n",
    "        df = pd.read_excel(path_to_results+f\"{prompt_id}/evaluation_results_has_no_criteria.xlsx\")\n",
    "        entry = {\n",
    "                'Prompt':mapping[prompt_id],\n",
    "                'Criteria Presence': 'without criteria only',\n",
    "                'Successful':0,\n",
    "                'Failed':0\n",
    "                }\n",
    "        for row in df.to_dict(orient='records'):\n",
    "            if row['conversion_status']=='ok':\n",
    "                entry['Successful']+=1\n",
    "            if row['conversion_status']=='failed':\n",
    "                entry['Failed']+=1\n",
    "        all_results.append(entry)\n",
    "    \n",
    "\n",
    "    \n",
    "    all_results_df = pd.DataFrame(all_results).sort_values(['Criteria Presence', 'Prompt'])\n",
    "    all_results_df = make_columns_bold(all_results_df)\n",
    "    return all_results_df\n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "print(make_formatting_overview().to_latex(index=False, float_format=\"{:.2f}\".format))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4d2f607f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>\\textbf{Prompt}</th>\n",
       "      <th>\\textbf{Criteria Presence}</th>\n",
       "      <th>\\textbf{Successful}</th>\n",
       "      <th>\\textbf{Failed}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>mixed</td>\n",
       "      <td>327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>mixed</td>\n",
       "      <td>327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>mixed</td>\n",
       "      <td>328</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>mixed</td>\n",
       "      <td>328</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>with criteria only</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>with criteria only</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>with criteria only</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>with criteria only</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>without criteria only</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>without criteria only</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>without criteria only</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>without criteria only</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   \\textbf{Prompt} \\textbf{Criteria Presence}  \\textbf{Successful}  \\\n",
       "0                1                      mixed                  327   \n",
       "3                2                      mixed                  327   \n",
       "6                3                      mixed                  328   \n",
       "9                4                      mixed                  328   \n",
       "1                1         with criteria only                  167   \n",
       "4                2         with criteria only                  167   \n",
       "7                3         with criteria only                  167   \n",
       "10               4         with criteria only                  167   \n",
       "2                1      without criteria only                  160   \n",
       "5                2      without criteria only                  160   \n",
       "8                3      without criteria only                  161   \n",
       "11               4      without criteria only                  161   \n",
       "\n",
       "    \\textbf{Failed}  \n",
       "0                 1  \n",
       "3                 1  \n",
       "6                 0  \n",
       "9                 0  \n",
       "1                 0  \n",
       "4                 0  \n",
       "7                 0  \n",
       "10                0  \n",
       "2                 1  \n",
       "5                 1  \n",
       "8                 0  \n",
       "11                0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_formatting_overview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47183a1d-d4ee-4010-8115-fc24c31b80d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1f7433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe826de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
